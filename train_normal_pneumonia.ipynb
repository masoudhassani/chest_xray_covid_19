{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "# LOGGING CONFIG ##############################\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "using the chest x-ray dataset from https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia/\n",
    "check if the chest x-ray dataset exists\n",
    "unzip the chest x-ray dataset if it exists\n",
    "'''\n",
    "if not os.path.exists('chest_xray'):\n",
    "    if os.path.exists('chest-xray-pneumonia.zip'):\n",
    "        logging.info('unzipping the dataset file')\n",
    "        os.system('unzip chest-xray-pneumonia.zip')\n",
    "        logging.info('unzipping is done')\n",
    "        os.system('rm chest-xray-pneumonia.zip')\n",
    "    else:\n",
    "        logging.warning('please download the dataset from https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "def create_data_from_image(dir, data_type, main, size):\n",
    "    data = []\n",
    "    occurrence = [0, 0, 0]\n",
    "    for cat in main:\n",
    "        logging.info('reading images for category {}'.format(cat))\n",
    "        path =  os.path.join(dir, data_type, cat)\n",
    "        label = main.index(cat)\n",
    "        for img in os.listdir(path):\n",
    "            # read and resize image\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                img_array = cv2.resize(img_array, (size, size))\n",
    "\n",
    "                # append to training data\n",
    "                occurrence[label] += 1\n",
    "                data.append([img_array, label])\n",
    "\n",
    "            except:\n",
    "                logging.warn('error reading {}'.format(img))\n",
    "    \n",
    "    logging.info('reading images done')\n",
    "    return data, occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'chest_xray'\n",
    "data_type = 'train'   # choose between train and test\n",
    "main_category = ['NORMAL', 'PNEUMONIA']\n",
    "image_size = 200\n",
    "\n",
    "# create training data with labels: 0:normal, 1:bacterial 2:viral\n",
    "training_data, occurrence = create_data_from_image(directory, data_type, main_category, image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# number of images with labels 0, 1\n",
    "print('Normal:', occurrence[0], 'Pneumonia:', occurrence[1])\n",
    "# weight is labels based on their occurence\n",
    "weight = [float(i)/sum(occurrence) for i in occurrence]\n",
    "print('Normal:', weight[0], 'Pneumonia:', weight[1])\n",
    "class_weight = {0: weight[0],\n",
    "                1: weight[1]}\n",
    "\n",
    "# shuffle the training data otherwise the neural network model will be inefficient\n",
    "import random \n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate features and labels\n",
    "X = []\n",
    "y = []\n",
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to convert a list to a numpy array that is understandable for tensorflow\n",
    "# -1 means everything in the list, 1 is because the image is gray scale\n",
    "X = np.array(X).reshape(-1, image_size, image_size, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the training data\n",
    "# you need at least 8GB of ram for this\n",
    "import pickle\n",
    "pickle_out = open('trainings/X_2labels.pickle', 'wb')\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open('trainings/y_2labels.pickle', 'wb')\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the following to read X and y in case we want to re run from here\n",
    "# this avoids the need to re-read all images\n",
    "# import pickle\n",
    "# X = pickle.load(open('trainings/X_2labels.pickle', 'rb'))\n",
    "# y = pickle.load(open('trainings/y_2labels.pickle', 'rb'))\n",
    "\n",
    "# in case of gray scale image data, we normalize it \n",
    "X = X/255.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test data\n",
    "directory = 'chest_xray'\n",
    "data_type = 'test'   # choose between train and test\n",
    "main_category = ['NORMAL', 'PNEUMONIA']\n",
    "image_size = 200\n",
    "\n",
    "# create training data with labels: 0:normal, 1:bacterial 2:viral\n",
    "test_data, occurrence = create_data_from_image(directory, data_type, main_category, image_size)\n",
    "\n",
    "# separate features and labels\n",
    "X_test = []\n",
    "y_test = []\n",
    "for features, label in test_data:\n",
    "    X_test.append(features)\n",
    "    y_test.append(label)\n",
    "\n",
    "X_test = np.array(X_test).reshape(-1, image_size, image_size, 1)\n",
    "X_test = X_test/255.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries to create neural networks\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "NAME = 'xray-2_labels-4_layers-64x32-{}'.format(int(time.time()))\n",
    "# tensorboard = TensorBoard(log_dir='trainings/{}'.format(NAME))\n",
    "# os.system(\"tensorboard --logdir='trainin/'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(X):\n",
    "    # create the model \n",
    "    model = Sequential() \n",
    "\n",
    "    # layer 1\n",
    "    model.add(Conv2D(64, (4, 4), strides=(3, 3), input_shape=X.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    # model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    # layer 2\n",
    "    model.add(Conv2D(32, (4, 4), strides=(3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # layer 3\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # output layer, we use Dense(3) to have 3 labels 0,1,2\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "model = create_model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case data is imported, chage the weight manually\n",
    "class_weight = {0: 0.25,\n",
    "                1: 0.75}\n",
    "# train the model with \n",
    "model.fit(X, y, batch_size=100, epochs=10, class_weight=class_weight, validation_split=0.1)\n",
    "# model.fit(X, y, batch_size=100, epochs=20, class_weight=class_weight, validation_split=0.1, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model again with external test data\n",
    "model.fit(X, y, batch_size=100, epochs=10, class_weight=class_weight, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the network weights\n",
    "model.save(\"trainings/{}.h5\".format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test the already saved weight\n",
    "# # create the model\n",
    "# model_test = create_model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load a weights\n",
    "# import tkinter as tk\n",
    "# from tkinter import filedialog\n",
    "\n",
    "# # file dialogue initialization\n",
    "# root = tk.Tk()\n",
    "# root.withdraw()\n",
    "\n",
    "# file_path = filedialog.askopenfilename(filetypes=[(\"Model Weights\", \".h5\")])\n",
    "# model_test.load_weights(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # evaluate the model\n",
    "# loss,acc = model_test.evaluate(X_test, y_test, verbose=2)\n",
    "# print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bittfvenvc7eebf1f4b234859800ec2a4f8559337",
   "display_name": "Python 3.6.9 64-bit ('tf': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}