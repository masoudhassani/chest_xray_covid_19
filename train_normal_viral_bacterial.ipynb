{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "# LOGGING CONFIG ##############################\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "using the chest x-ray dataset from https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia/\n",
    "check if the chest x-ray dataset exists\n",
    "unzip the chest x-ray dataset if it exists\n",
    "'''\n",
    "if not os.path.exists('chest_xray'):\n",
    "    if os.path.exists('chest-xray-pneumonia.zip'):\n",
    "        logging.info('unzipping the dataset file')\n",
    "        os.system('unzip chest-xray-pneumonia.zip')\n",
    "        logging.info('unzipping is done')\n",
    "        os.system('rm chest-xray-pneumonia.zip')\n",
    "    else:\n",
    "        logging.warning('please download the dataset from https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "2020-05-14 15:42:44 INFO     reading images for category NORMAL\n2020-05-14 15:43:11 INFO     reading images for category PNEUMONIA\n2020-05-14 15:43:35 INFO     reading images done\n"
    }
   ],
   "source": [
    "def create_data_from_image(dir, data_type, main, sub, size):\n",
    "    training_data = []\n",
    "    occurrence = [0, 0, 0]\n",
    "    for cat in main:\n",
    "        logging.info('reading images for category {}'.format(cat))\n",
    "        path =  os.path.join(dir, data_type, cat)\n",
    "        label = main.index(cat)\n",
    "        for img in os.listdir(path):\n",
    "            # read and resize image\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                img_array = cv2.resize(img_array, (size, size))\n",
    "\n",
    "                # assign label for virus and bateria\n",
    "                if label != 0:\n",
    "                    if sub[0] in img:\n",
    "                        label = 1\n",
    "                    else:\n",
    "                        label = 2\n",
    "\n",
    "                # append to training data\n",
    "                occurrence[label] += 1\n",
    "                training_data.append([img_array, label])\n",
    "\n",
    "            except:\n",
    "                logging.warn('error reading {}'.format(img))\n",
    "    \n",
    "    logging.info('reading images done')\n",
    "    return training_data, occurrence\n",
    "\n",
    "            \n",
    "directory = 'chest_xray'\n",
    "data_type = 'train'   # choose between train and test\n",
    "main_category = ['NORMAL', 'PNEUMONIA']\n",
    "sub_category = ['bacteria', 'virus']\n",
    "image_size = 200\n",
    "\n",
    "# create training data with labels: 0:normal, 1:bacterial 2:viral\n",
    "training_data, occurrence = create_data_from_image(directory, data_type, main_category, sub_category, image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Normal: 1341 Bacterial: 2530 Viral: 1345\nNormal: 0.2570935582822086 Bacterial: 0.48504601226993865 Viral: 0.25786042944785276\n"
    }
   ],
   "source": [
    "# # number of images with labels 0, 1 and 2\n",
    "print('Normal:', occurrence[0], 'Bacterial:', occurrence[1], 'Viral:', occurrence[2])\n",
    "# weight is labels based on their occurence\n",
    "weight = [float(i)/sum(occurrence) for i in occurrence]\n",
    "print('Normal:', weight[0], 'Bacterial:', weight[1], 'Viral:', weight[2])\n",
    "class_weight = {0: weight[0],\n",
    "                1: weight[1],\n",
    "                2: weight[2]}\n",
    "\n",
    "# shuffle the training data otherwise the neural network model will be inefficient\n",
    "import random \n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate features and labels\n",
    "X = []\n",
    "y = []\n",
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to convert a list to a numpy array that is understandable for tensorflow\n",
    "# -1 means everything in the list, 1 is because the image is gray scale\n",
    "X = np.array(X).reshape(-1, image_size, image_size, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the training data\n",
    "# you need at least 8GB of ram for this\n",
    "import pickle\n",
    "pickle_out = open('trainings/X_3labels.pickle', 'wb')\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open('trainings/y_3labels.pickle', 'wb')\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries to create neural networks\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the following to read X and y in case we want to re run from here\n",
    "# this avoids the need to re-read all images\n",
    "# import pickle\n",
    "# X = pickle.load(open('trainings/X_3labels.pickle', 'rb'))\n",
    "# y = pickle.load(open('trainings/y_3labels.pickle', 'rb'))\n",
    "\n",
    "# in case of gray scale image data, we normalize it \n",
    "X = X/255.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "NAME = 'xray-3_labels-4_layers-2x32-{}'.format(int(time.time()))\n",
    "# tensorboard = TensorBoard(log_dir='trainings/{}'.format(NAME))\n",
    "# os.system(\"tensorboard --logdir='trainin/'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "2020-05-14 15:43:40 WARNING  From /home/masoud/tf/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\nModel: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 50, 50, 32)        544       \n_________________________________________________________________\nactivation (Activation)      (None, 50, 50, 32)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 24, 24, 32)        16416     \n_________________________________________________________________\nactivation_1 (Activation)    (None, 24, 24, 32)        0         \n_________________________________________________________________\nflatten (Flatten)            (None, 18432)             0         \n_________________________________________________________________\ndense (Dense)                (None, 64)                1179712   \n_________________________________________________________________\nactivation_2 (Activation)    (None, 64)                0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 3)                 195       \n_________________________________________________________________\nactivation_3 (Activation)    (None, 3)                 0         \n=================================================================\nTotal params: 1,196,867\nTrainable params: 1,196,867\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
    }
   ],
   "source": [
    "# create the model \n",
    "model = Sequential() \n",
    "\n",
    "# layer 1\n",
    "model.add(Conv2D(32, (4,4), strides=(4, 4), input_shape=X.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# layer 2\n",
    "model.add(Conv2D(32, (4, 4), strides=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# layer 3\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# output layer, we use Dense(3) to have 3 labels 0,1,2\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 4694 samples, validate on 522 samples\nEpoch 1/20\n4694/4694 [==============================] - 9s 2ms/sample - loss: 0.2639 - acc: 0.6014 - val_loss: 0.1856 - val_acc: 0.7203\nEpoch 2/20\n4694/4694 [==============================] - 10s 2ms/sample - loss: 0.1822 - acc: 0.7409 - val_loss: 0.1727 - val_acc: 0.7625\nEpoch 3/20\n4694/4694 [==============================] - 9s 2ms/sample - loss: 0.1607 - acc: 0.7727 - val_loss: 0.1534 - val_acc: 0.7816\nEpoch 4/20\n4694/4694 [==============================] - 10s 2ms/sample - loss: 0.1532 - acc: 0.7844 - val_loss: 0.1529 - val_acc: 0.7854\nEpoch 5/20\n4694/4694 [==============================] - 9s 2ms/sample - loss: 0.1520 - acc: 0.7887 - val_loss: 0.1530 - val_acc: 0.7759\nEpoch 6/20\n4694/4694 [==============================] - 9s 2ms/sample - loss: 0.1405 - acc: 0.7951 - val_loss: 0.1674 - val_acc: 0.7567\nEpoch 7/20\n4694/4694 [==============================] - 9s 2ms/sample - loss: 0.1400 - acc: 0.8042 - val_loss: 0.1568 - val_acc: 0.7969\nEpoch 8/20\n4694/4694 [==============================] - 10s 2ms/sample - loss: 0.1338 - acc: 0.8115 - val_loss: 0.1563 - val_acc: 0.7720\nEpoch 9/20\n4694/4694 [==============================] - 10s 2ms/sample - loss: 0.1255 - acc: 0.8228 - val_loss: 0.1559 - val_acc: 0.7969\nEpoch 10/20\n4694/4694 [==============================] - 10s 2ms/sample - loss: 0.1252 - acc: 0.8204 - val_loss: 0.1555 - val_acc: 0.7950\nEpoch 11/20\n4694/4694 [==============================] - 10s 2ms/sample - loss: 0.1172 - acc: 0.8302 - val_loss: 0.1481 - val_acc: 0.7931\nEpoch 12/20\n4694/4694 [==============================] - 9s 2ms/sample - loss: 0.1133 - acc: 0.8406 - val_loss: 0.1511 - val_acc: 0.7989\nEpoch 13/20\n4694/4694 [==============================] - 10s 2ms/sample - loss: 0.1080 - acc: 0.8502 - val_loss: 0.1671 - val_acc: 0.7797\nEpoch 14/20\n4694/4694 [==============================] - 10s 2ms/sample - loss: 0.1026 - acc: 0.8577 - val_loss: 0.1808 - val_acc: 0.7663\nEpoch 15/20\n4694/4694 [==============================] - 9s 2ms/sample - loss: 0.0981 - acc: 0.8598 - val_loss: 0.1652 - val_acc: 0.7950\nEpoch 16/20\n4694/4694 [==============================] - 10s 2ms/sample - loss: 0.0914 - acc: 0.8709 - val_loss: 0.1642 - val_acc: 0.7874\nEpoch 17/20\n4694/4694 [==============================] - 10s 2ms/sample - loss: 0.0861 - acc: 0.8865 - val_loss: 0.1683 - val_acc: 0.7874\nEpoch 18/20\n4694/4694 [==============================] - 10s 2ms/sample - loss: 0.0756 - acc: 0.9014 - val_loss: 0.2022 - val_acc: 0.7701\nEpoch 19/20\n4694/4694 [==============================] - 10s 2ms/sample - loss: 0.0727 - acc: 0.9026 - val_loss: 0.1906 - val_acc: 0.7969\nEpoch 20/20\n4694/4694 [==============================] - 10s 2ms/sample - loss: 0.0664 - acc: 0.9116 - val_loss: 0.2107 - val_acc: 0.7816\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7fed0995eac8>"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=100, epochs=20, class_weight=class_weight, validation_split=0.1)\n",
    "# model.fit(X, y, batch_size=100, epochs=20, class_weight=class_weight, validation_split=0.1, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the network weights\n",
    "model.save_weights(\"trainings/{}.h5\".format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bittfvenvc7eebf1f4b234859800ec2a4f8559337",
   "display_name": "Python 3.6.9 64-bit ('tf': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}