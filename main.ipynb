{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "# LOGGING CONFIG ##############################\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "using the chest x-ray dataset from https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia/\n",
    "check if the chest x-ray dataset exists\n",
    "unzip the chest x-ray dataset if it exists\n",
    "'''\n",
    "if not os.path.exists('chest_xray'):\n",
    "    if os.path.exists('chest-xray-pneumonia.zip'):\n",
    "        logging.info('unzipping the dataset file')\n",
    "        os.system('unzip chest-xray-pneumonia.zip')\n",
    "        logging.info('unzipping is done')\n",
    "        os.system('rm chest-xray-pneumonia.zip')\n",
    "    else:\n",
    "        logging.warning('please download the dataset from https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "2020-05-13 15:13:22 INFO     reading images for category NORMAL\n2020-05-13 15:13:47 INFO     reading images for category PNEUMONIA\n2020-05-13 15:14:07 INFO     reading images done\n"
    }
   ],
   "source": [
    "def create_training_data(dir, data_type, main, sub, size):\n",
    "    training_data = []\n",
    "    occurrence = [0, 0, 0]\n",
    "    for cat in main:\n",
    "        logging.info('reading images for category {}'.format(cat))\n",
    "        path =  os.path.join(dir, data_type, cat)\n",
    "        label = main.index(cat)\n",
    "        for img in os.listdir(path):\n",
    "            # read and resize image\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                img_array = cv2.resize(img_array, (size, size))\n",
    "\n",
    "                # assign label for virus and bateria\n",
    "                if label != 0:\n",
    "                    if sub[0] in img:\n",
    "                        label = 1\n",
    "                    else:\n",
    "                        label = 2\n",
    "\n",
    "                # append to training data\n",
    "                occurrence[label] += 1\n",
    "                training_data.append([img_array, label])\n",
    "\n",
    "            except:\n",
    "                logging.warn('error reading {}'.format(img))\n",
    "    \n",
    "    logging.info('reading images done')\n",
    "    return training_data, occurrence\n",
    "\n",
    "            \n",
    "directory = 'chest_xray'\n",
    "data_type = 'train'   # choose between train and test\n",
    "main_category = ['NORMAL', 'PNEUMONIA']\n",
    "sub_category = ['bacteria', 'virus']\n",
    "image_size = 400\n",
    "\n",
    "# create training data with labels: 0:normal, 1:bacterial 2:viral\n",
    "training_data, occurrence = create_training_data(directory, data_type, main_category, sub_category, image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Normal: 1341 Bacterial: 2530 Viral: 1345\nNormal: 0.2570935582822086 Bacterial: 0.48504601226993865 Viral: 0.25786042944785276\n"
    }
   ],
   "source": [
    "# number of images with labels 0, 1 and 2\n",
    "print('Normal:', occurrence[0], 'Bacterial:', occurrence[1], 'Viral:', occurrence[2])\n",
    "# weight is labels based on their occurence\n",
    "weight = [float(i)/sum(occurrence) for i in occurrence]\n",
    "print('Normal:', weight[0], 'Bacterial:', weight[1], 'Viral:', weight[2])\n",
    "\n",
    "# shuffle the training data otherwise the neural network model will be inefficient\n",
    "import random \n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate features and labels\n",
    "X = []\n",
    "y = []\n",
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to convert a list to a numpy array that is understandable for tensorflow\n",
    "# -1 means everything in the list, 1 is because the image is gray scale\n",
    "X = np.array(X).reshape(-1, image_size, image_size, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the training data\n",
    "import pickle\n",
    "pickle_out = open('trainings/X.pickle', 'wb')\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open('trainings/y.pickle', 'wb')\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bittfvenvc7eebf1f4b234859800ec2a4f8559337",
   "display_name": "Python 3.6.9 64-bit ('tf': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}